{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWVJpDjerKDM1MKzdIfmdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/tensorflow-fundamentals/blob/master/01_neural_network_regression_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. Neural Network Regression with TensorFlow\n",
        "\n",
        "In this notebook, we're going to set the foundations for how you can take a sample of inputs(this is our data), build a neural network to discover patterns in those inputs and then make a prediction(in form of a number) based on those inputs."
      ],
      "metadata": {
        "id": "W6f0UacUZj40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typical Architecture of Regression Neural Network\n",
        "\n",
        "The word *typical* is on purpose.\n",
        "\n",
        "Why?\n",
        "\n",
        "Because there are many different ways (actually, there's almost an infinite number of ways) to write neural network.\n",
        "\n",
        "But the following is a generic setup for ingesting a collection of numbers, finding patterns in them and then outputing some kind of target number.\n",
        "\n",
        "\n",
        "| **Hyperparameter** | **Typical value** |\n",
        "| --- | --- |\n",
        "| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |\n",
        "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
        "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
        "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
        "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n",
        "| Output activation | None, ReLU, logistic/tanh |\n",
        "| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n",
        "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n",
        "\n",
        "***Table 1:*** *Typical architecture of a regression network.* ***Source:*** *Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by AurÃ©lien GÃ©ron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n"
      ],
      "metadata": {
        "id": "2yMovR5Ei1Yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ðŸ”‘ **Note**: A **hyperparameter** in machine learning is something a data analyst or developer can set themselves, where as a **parameter** usually describes something a model learns on its own (a value not explicitly set by an analyst)."
      ],
      "metadata": {
        "id": "-m6-iIs7j8aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the tensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5DzVSjBk5p5",
        "outputId": "61ac855a-67ed-4261-e65c-b00bec6139a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data to view and fit\n",
        "\n",
        "Since we're working on a regression problem (predicting a number), let's create some linear data (a straight line) to model."
      ],
      "metadata": {
        "id": "LsFdN0L2m5Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([-3.0, 0.0, 3.0, 6.0, 9.0, 12.0, 15.0, 18.0])\n",
        "\n",
        "# Visualise it\n",
        "plt.scatter(X,y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "12LMC9ADnLj3",
        "outputId": "a85faea9-9086-4404-b9da-c38ea3ad9559"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we do any modelling, can we calculate the pattern between X and y?\n",
        "\n",
        "For example, say I asked you, based on this data what the y value would be if X was 17.0 ?\n",
        "\n",
        "or how about if X was -10.0 ?\n",
        "\n",
        "This kind of pattern discovery is the essence of what we'll be building neural networks to do for us."
      ],
      "metadata": {
        "id": "GfE5U1OAnRe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression input shapes and output shapes\n",
        "\n",
        "One of the most important concepts when working with neural networks are the input and output shapes.\n",
        "\n",
        "The **input shape** is the shape of your data that goes into the model.\n",
        "The **output shape** is the shape of your data you want to come out of your model.\n",
        "\n",
        "These will differ depending on the problem you're working on.\n",
        "\n",
        "Neural networks accept numbers and output numbers. These numbers are typically represented as tensors(or arrays).\n",
        "\n",
        "Before, we created data using Numpy arrays, but we could do the same with tensors."
      ],
      "metadata": {
        "id": "Nhwn395rpYZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input and output shapes of a regression model\n",
        "house_info = tf.constant([\"bedroom\",\"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5ifuXF5uz49",
        "outputId": "1403bc74-4b51-4210-efb2-99cbcc0fa5a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_info.shape, house_price.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go-zW8dQvEzF",
        "outputId": "782d877f-7204-4af9-f2d3-1baea0b5cdf1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([3]), TensorShape([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It says input shape as 3, and output shape is 1"
      ],
      "metadata": {
        "id": "YAOQb8jdvowI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![example of input and output shapes for a housing price prediction problem](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png)\n",
        "\n",
        "*If we were working on building a machine learning algorithm for predicting housing prices, our inputs may be number of bedrooms, number of bathrooms and number of garages, giving you an input shape of 3 (3 different features). And since we are trying to predict the price of the house, our output shape would be 1.*"
      ],
      "metadata": {
        "id": "1r52eIn2vtWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "Now we know what data we have as well as the input and output shapes, let's see how we'd build a neural network to model it.\n",
        "\n",
        "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
        "\n",
        "1. **Creating a model**: piece together the layers of a neural network yourself (using Functional or Sequential API) or import a previously build model (known as transfer learning).\n",
        "2. **Compiling a model**: defining how a model performance should be measured(loss/metrics) as well as defining how it should improve(optimizer)\n",
        "3. **Fitting a model**: letting the model try to find patterns in the data(how does x get to y)\n",
        "\n",
        "\n",
        "Let's see using the Keras Sequential API to build a model for our regression problem."
      ],
      "metadata": {
        "id": "2V3Y_GjZw4FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the random see\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Dense means, fully connected layer, it means all the neurons are connected with all the neurons of the next layer\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(loss= tf.keras.losses.mae, # Mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(), # Stochastic gradient descent\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(X, axis = -1), y, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIK-rK-PyYlJ",
        "outputId": "07467118-8019-4d77-d879-de70eedbb900"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 613ms/step - loss: 5.5048 - mae: 5.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.3723 - mae: 5.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2398 - mae: 5.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1073 - mae: 5.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9748 - mae: 4.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82b198a490>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've just trained a model to figure out the patterns between X and y\n"
      ],
      "metadata": {
        "id": "IVs1iOFgzZqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdeuHOZSzobM",
        "outputId": "cdfbe590-27d0-4e6e-a0f2-6239d62d9841"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-7., -4., -1.,  2.,  5.,  8., 11., 14.]),\n",
              " array([-3.,  0.,  3.,  6.,  9., 12., 15., 18.]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think the outcome should be if we passed our model an x value of 17.0 ?\n"
      ],
      "metadata": {
        "id": "_B_iEtluzqSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction with the model\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfEHXWfnzzK8",
        "outputId": "5715cdaf-cb50-4c98-968b-57b09ea79b7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "12.71 + 4.97 # adding with our model's loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRDgEX-R0YhF",
        "outputId": "bdba594d-4498-4015-da42-247847b787ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.68"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It doesn't went well.. it should've output something close to 21.0\n",
        "\n",
        "> ðŸ¤” **What's Keras ?** : I thought we were working with TensorFLow but everytime we write TensorFlow code, `keras` comes after `tf` (e.g `tf.keras.layers.Dense()`) ?\n",
        "\n",
        "Before TensorFlow 2.0+, Keras was an API designed to be able to build deep learning models with ease. Since TensorFlow 2.0+, its functionality has been tightly integrated withing the TensorFlow Library."
      ],
      "metadata": {
        "id": "UW63yVq00dqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving a model\n",
        "\n",
        "To improve our model, we alter almost every part of 3 steps we went through before.\n",
        "\n",
        "1. **Creating a model**: here we might add some more layers, increase the number of hidden units (also called as neurons) within each layer, change the activation functions of each layer.\n",
        "2. **Compiling a model**: we might want to choose different optimization function or perhaps change the **learning rate** of the optimization function.\n",
        "3. **Fitting a model**: perhaps we might want to train on more data or we could fit a model for more **epochs** (leave it training for longer)\n",
        "\n",
        "![improve a model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-improving-a-model-from-model-perspective.png)\n",
        "\n",
        "*There are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as hyperparameters and the practice of trying to find the best hyperparameters is referred to as hyperparameter tuning.*\n",
        "\n",
        "\n",
        "\n",
        "For now, let's keep it simple, all we'll do is to train our model for longer (everything else will stay the same)"
      ],
      "metadata": {
        "id": "T0K_Iedy1kM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# compile a model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# fitting a model\n",
        "model.fit(tf.expand_dims(X, axis = -1),y,epochs = 100)"
      ],
      "metadata": {
        "id": "coYGyqg41m8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b504368-e15a-4950-9eca-22abbfa49cd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 5.5048 - mae: 5.5048\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3723 - mae: 5.3723\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2398 - mae: 5.2398\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1073 - mae: 5.1073\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9748 - mae: 4.9748\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8423 - mae: 4.8423\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7098 - mae: 4.7098\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5773 - mae: 4.5773\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4448 - mae: 4.4448\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3123 - mae: 4.3123\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1798 - mae: 4.1798\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0473 - mae: 4.0473\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9148 - mae: 3.9148\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7823 - mae: 3.7823\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6498 - mae: 3.6498\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5173 - mae: 3.5173\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3848 - mae: 3.3848\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2523 - mae: 3.2523\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1198 - mae: 3.1198\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9873 - mae: 2.9873\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8548 - mae: 2.8548\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8425 - mae: 2.8425\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8369 - mae: 2.8369\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8312 - mae: 2.8312\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8256 - mae: 2.8256\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8200 - mae: 2.8200\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8144 - mae: 2.8144\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8087 - mae: 2.8087\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.8031 - mae: 2.8031\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7975 - mae: 2.7975\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7919 - mae: 2.7919\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7863 - mae: 2.7863\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7806 - mae: 2.7806\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7750 - mae: 2.7750\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7694 - mae: 2.7694\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7638 - mae: 2.7638\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7581 - mae: 2.7581\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7525 - mae: 2.7525\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7469 - mae: 2.7469\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7413 - mae: 2.7413\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7356 - mae: 2.7356\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7300 - mae: 2.7300\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7244 - mae: 2.7244\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7188 - mae: 2.7188\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7131 - mae: 2.7131\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7075 - mae: 2.7075\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7019 - mae: 2.7019\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6963 - mae: 2.6963\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6906 - mae: 2.6906\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6850 - mae: 2.6850\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6794 - mae: 2.6794\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6738 - mae: 2.6738\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6681 - mae: 2.6681\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6625 - mae: 2.6625\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6569 - mae: 2.6569\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6513 - mae: 2.6513\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6456 - mae: 2.6456\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6400 - mae: 2.6400\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6344 - mae: 2.6344\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6288 - mae: 2.6288\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6231 - mae: 2.6231\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6175 - mae: 2.6175\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6119 - mae: 2.6119\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6063 - mae: 2.6063\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6006 - mae: 2.6006\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5950 - mae: 2.5950\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5894 - mae: 2.5894\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5838 - mae: 2.5838\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5781 - mae: 2.5781\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5725 - mae: 2.5725\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5669 - mae: 2.5669\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5613 - mae: 2.5613\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5556 - mae: 2.5556\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5500 - mae: 2.5500\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5444 - mae: 2.5444\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5388 - mae: 2.5388\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5331 - mae: 2.5331\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5275 - mae: 2.5275\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5219 - mae: 2.5219\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5164 - mae: 2.5164\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5125 - mae: 2.5125\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5069 - mae: 2.5069\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5013 - mae: 2.5013\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4956 - mae: 2.4956\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4900 - mae: 2.4900\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4844 - mae: 2.4844\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4788 - mae: 2.4788\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4731 - mae: 2.4731\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4675 - mae: 2.4675\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4619 - mae: 2.4619\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4563 - mae: 2.4563\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4506 - mae: 2.4506\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4450 - mae: 2.4450\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4394 - mae: 2.4394\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4338 - mae: 2.4338\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4281 - mae: 2.4281\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4225 - mae: 2.4225\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4169 - mae: 2.4169\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4113 - mae: 2.4113\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4056 - mae: 2.4056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82b61edad0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you notice, we have minimised the loss just below 2.5 which was almost 5 when we were fitting the model with 5 `epochs`"
      ],
      "metadata": {
        "id": "51wl8sxvKe_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see X & y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLJUyasLBXc",
        "outputId": "180b86ab-19cd-4e70-d83e-235c455de778"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-7., -4., -1.,  2.,  5.,  8., 11., 14.]),\n",
              " array([-3.,  0.,  3.,  6.,  9., 12., 15., 18.]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction with improved model\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mfCXNrPLFGM",
        "outputId": "b7a6ab26-1a40-454e-99a9-cfd509c768be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.518517]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It should predict around 21.0, so our model is almost closer to the correct predictions.\n",
        "\n",
        "Let's try tuning other hyperparameters,\n",
        "\n",
        "This time, we will choose different optimizer function"
      ],
      "metadata": {
        "id": "vUXd5v3dLOIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# again do the same process,\n",
        "\n",
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# compile a model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # lr stands for learning rate\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# fit a model\n",
        "model.fit(tf.expand_dims(X, axis = -1), y, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx9GPFbwLaGL",
        "outputId": "0b754146-5d56-42f1-a7cd-103d5c7c9dc7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 5.5048 - mae: 5.5048\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5043 - mae: 5.5043\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5039 - mae: 5.5039\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5034 - mae: 5.5034\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5030 - mae: 5.5030\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5025 - mae: 5.5025\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5021 - mae: 5.5021\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5016 - mae: 5.5016\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5012 - mae: 5.5012\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5007 - mae: 5.5007\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5003 - mae: 5.5003\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4998 - mae: 5.4998\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4994 - mae: 5.4994\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4989 - mae: 5.4989\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4985 - mae: 5.4985\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4980 - mae: 5.4980\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4976 - mae: 5.4976\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4971 - mae: 5.4971\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4967 - mae: 5.4967\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4962 - mae: 5.4962\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4958 - mae: 5.4958\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4953 - mae: 5.4953\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4949 - mae: 5.4949\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4944 - mae: 5.4944\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4940 - mae: 5.4940\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4935 - mae: 5.4935\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4931 - mae: 5.4931\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4926 - mae: 5.4926\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4922 - mae: 5.4922\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4917 - mae: 5.4917\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4913 - mae: 5.4913\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4908 - mae: 5.4908\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4904 - mae: 5.4904\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4899 - mae: 5.4899\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4895 - mae: 5.4895\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4890 - mae: 5.4890\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4886 - mae: 5.4886\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4881 - mae: 5.4881\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4877 - mae: 5.4877\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4872 - mae: 5.4872\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4868 - mae: 5.4868\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4863 - mae: 5.4863\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4859 - mae: 5.4859\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4854 - mae: 5.4854\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4850 - mae: 5.4850\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4845 - mae: 5.4845\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4841 - mae: 5.4841\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.4836 - mae: 5.4836\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.4832 - mae: 5.4832\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4827 - mae: 5.4827\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4823 - mae: 5.4823\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4818 - mae: 5.4818\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4814 - mae: 5.4814\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4809 - mae: 5.4809\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4805 - mae: 5.4805\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4800 - mae: 5.4800\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4796 - mae: 5.4796\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4791 - mae: 5.4791\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4787 - mae: 5.4787\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4782 - mae: 5.4782\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4778 - mae: 5.4778\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4773 - mae: 5.4773\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4769 - mae: 5.4769\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4764 - mae: 5.4764\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4760 - mae: 5.4760\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4755 - mae: 5.4755\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4751 - mae: 5.4751\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4746 - mae: 5.4746\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4742 - mae: 5.4742\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4737 - mae: 5.4737\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4733 - mae: 5.4733\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4728 - mae: 5.4728\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4724 - mae: 5.4724\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4719 - mae: 5.4719\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4715 - mae: 5.4715\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4710 - mae: 5.4710\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4706 - mae: 5.4706\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4701 - mae: 5.4701\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4697 - mae: 5.4697\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4692 - mae: 5.4692\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4688 - mae: 5.4688\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.4683 - mae: 5.4683\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.4679 - mae: 5.4679\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4674 - mae: 5.4674\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4670 - mae: 5.4670\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4665 - mae: 5.4665\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4661 - mae: 5.4661\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4656 - mae: 5.4656\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4652 - mae: 5.4652\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4647 - mae: 5.4647\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4643 - mae: 5.4643\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4638 - mae: 5.4638\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4634 - mae: 5.4634\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4629 - mae: 5.4629\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4625 - mae: 5.4625\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4620 - mae: 5.4620\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4616 - mae: 5.4616\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4611 - mae: 5.4611\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4607 - mae: 5.4607\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4602 - mae: 5.4602\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82b0df5a90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Goi7zpzEMyCv",
        "outputId": "4bc8998a-0a5c-4225-f2c5-a7a9e498df8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.871047]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is possible that not always tweaking with hyperparameters will get closer to the correct results, like in this case, our model performs worse than previous tuning, it means `Adam()` function is not right for this model. \n",
        "\n",
        "Hence, that's idea behind tweaking and improving our model, to find out best possible hyperparameters to build a perfect model."
      ],
      "metadata": {
        "id": "3JBGFRBaNBj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "A typical workflow you'll go through when building neural network is:\n",
        "\n",
        "`Build a model -> evaluate it -> build (tweak) a model -> evaluate it -> build (tweak) a model -> evaluate it...`\n",
        "\n",
        "The tweaking comes from maybe not building a model from scratch but adjusting existing one.\n",
        "\n",
        "\n",
        "When it comes to evaluation, we must remember these 3 words:\n",
        "> **Visualise, Visualise, Visualise**\n",
        "\n",
        "This is because we're probably better looking at something(doing) than we are thinking about something.\n",
        "\n",
        "It's a good idea to visualise:\n",
        "* **The data** - what data are we working with? What does it look like?\n",
        "* **The model itself** - what does the architecture look like? What are the different shapes.\n",
        "* **The training of a model** - how does a model perform while it learns ?\n",
        "* **The predictions of a model** - how do the predictions of a model line up against the ground truth (the original labels)?\n",
        "\n",
        "Let's visualising our model,\n",
        "\n",
        "But first we need to create a little bit of a bigger dataset and a new model we can use."
      ],
      "metadata": {
        "id": "OSbH_Kd0Nrff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100,100,4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqNKZ34zbJ2K",
        "outputId": "670da701-0479-4a0e-d447-759c41039b42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make labels for the dataset\n",
        "# we want our model to learn the model as y = X + 5\n",
        "y = X + 5\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4WmhcRic3i0",
        "outputId": "600dd0bb-6dff-4d0b-c0f4-632edb5f414e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-95, -91, -87, -83, -79, -75, -71, -67, -63, -59, -55, -51, -47,\n",
              "       -43, -39, -35, -31, -27, -23, -19, -15, -11,  -7,  -3,   1,   5,\n",
              "         9,  13,  17,  21,  25,  29,  33,  37,  41,  45,  49,  53,  57,\n",
              "        61,  65,  69,  73,  77,  81,  85,  89,  93,  97, 101], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training/test set\n",
        "\n",
        "Usually when dealing with real-world data, spliting is typically done right at the start of the project (the test set should always be kept separate from all other data).\n",
        "\n",
        "We want our model to learn on training data and then evaluate it on test data to get an indication of how well it generalizes to unseen examples."
      ],
      "metadata": {
        "id": "s_Z1Zuy0dA8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the number of samples we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP8buvVYjIXS",
        "outputId": "46f75a4f-57f4-4452-f7c9-69078811c0cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train = X[:40]  # first 40 examples (80% of data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 examples (20% of data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uekAQyc_jLml",
        "outputId": "48c70b96-9534-4c85-8419-822c94f6ef92"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's visualise it using the plots"
      ],
      "metadata": {
        "id": "F7lIXR5ojl_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualise the data"
      ],
      "metadata": {
        "id": "KzL9B1GBjuFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "# plot the training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training Data\")\n",
        "\n",
        "# Plot the test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
        "\n",
        "# Show the legend\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Tp9DHssXjwxc",
        "outputId": "dffdaf29-4db1-4ab8-cddc-b3aa1ca8066b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any time we can visualise our data, our model, our anything. It's a good idea.\n",
        "\n",
        "\n",
        "Keeping this graph in our mind, what we'll be trying is to build a model which learns the pattern in the blue dots (`X_train`) to draw the green dots (`X_test`)\n",
        "\n",
        "So, let's build our model."
      ],
      "metadata": {
        "id": "Eg02XDBckhjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer= tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "# model.fit(X_train, y_train, epochs = 100) # commented out on purpose, first we will visualise the model"
      ],
      "metadata": {
        "id": "NuEBZpRFlKTO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualise the model\n",
        "\n",
        "After we've built a model, we might want to visualise the layers and shapes of our model, by called `summary()` on it.\n",
        "\n",
        "> ðŸ”‘ **Note**: Visualizing a model is particularly helpful when you run into input and output shapes mismatches.\n"
      ],
      "metadata": {
        "id": "axSQcA1Tl8AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "0evj4qiMmbAF",
        "outputId": "766584c8-7ed8-428d-f2ae-838cf5050e0f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4954ad8269f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's see the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2870\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the model is not built, it's not showing us the summary.\n",
        "\n",
        "We also haven't defined the input the shape while creating a model, it we define the input shape while creating a model, it will automatically build the model.\n",
        "\n",
        "So what's the input shape of our dataset ?"
      ],
      "metadata": {
        "id": "_K-zZFzNmf__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since our prediction would be predicting 1 y value from 1 X value, it means X[0] will be the shape of our input\n",
        "X[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvyxe1vDms8S",
        "outputId": "24e45899-43da-4360-d6cf-45e8297101fc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, our `input_shape` is `[1]`.\n",
        "\n",
        "**Note:** Usually if input_shape isn't defined, Keras tries to figure it out automatically."
      ],
      "metadata": {
        "id": "IdJRwcnknCPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model again\n",
        "\n",
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(3, input_shape=[1]) # define the input_shape of our model\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "9ObI5rTQni75"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-a71NC0oAnt",
        "outputId": "308ae7cd-f77c-4260-a5d0-a71cd1693353"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 3)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling `summary()` on our model shows us the layers it contains, the output shape and the number of parameters.\n",
        "\n",
        "* **Total Params**: Total number of parameters in the model\n",
        "* **Trainable params**: These are the parameters(patterns) the model can update as it trains.\n",
        "* **Non-Trainable params**: These parameters aren't updated during training(this is typical when you bring in the already learned patterns from other models during transfer learning).\n",
        "\n",
        "> ðŸ“– **Resource**: For a more in-depth overview of the trainabel parameters within a layer, check out [MIT's introduction to deep learning video](https://youtu.be/njKP3FqW3Sk)\n",
        "\n",
        "> ðŸ›  **Exercise**: Try playing around with the number of hidden units in the `Dense` Layer (e.g `Dense(2)`, `Dense(3)`). How does this change the Total/Trainable params ? Investigate what's causing the change."
      ],
      "metadata": {
        "id": "gCvk48ZZoCYL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "covrTjq7puns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}